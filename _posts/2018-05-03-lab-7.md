---
title: "Classifier 2"
header:
  teaser: /assets/images/Lab7.png
categories:
  - Digital Signal Processing
tags:
  - tone shifting
  - fourier
  - peak power
toc: true
---

# Introduction
In this project we use Fourier transforms, power specs, peak power, and chroma shifting to create a different type of classifier to identify the genre of music tracks. 

<figure>
	<a href="/assets/images/Lab7.png"><img src="/assets/images/Lab7.png"></a>
</figure>

# Main Project

## Part 1: Short Time Fourier Transform

Below are the figures generated using the function with the Hann window. The code used to generate the plots is found in the appendix at the end of the report. Comments on the results of each track for the stft are given above each figure. Comments for the rest of the figures in the report will also use the Hann window. Stft takes in the sampled signal as well as which window will be used. The Hann window in the case of this report, but the Kaiser and Blackman window could be used as well by changing the second argument of the function. The function produces a time-frequency matrix where each column of the matrix is the frequency response of 1024 sample section of a song, and the sections overlap by 768 samples each. All songs are analyzed individually in the following section. 

For track201-classical.wav we can see that there are many different notes being played which makes sense as this is piece is better known as Violin Concerto No. 1 in A minor by Bach. This makes sense for a concerto, as the definition of a concerto is a musical piece where there is a main instrument, which in this case is a violin, accompanied by an orchestra which can include many different instruments. It can be seen that the main spots of red at lower frequencies is likely the steady beat and harmony that can be heard from the cello, while the higher frequencies are the melodies of the first set of violins and the overtones of the second set of violins. It is also important to note that while it is not as noticeable to the ear, the chart shows as slight decrease in frequency as time goes on which can likely be attributed to the nature of string instruments as the vibrations caused between the string and the bow can cause the string to loosen, thus generating lower frequencies than intended. 

![Figure71]({{ site.url }}/assets/images/figure7-1.PNG)

In track204-classical.wav, the melody can be clearly seen as there is only one instrument playing which is a piano. As this is just a standard etude (practice exercise) the track follows a very standard pattern of increasing frequencies and then decreasing frequencies. We can see some spikes in frequency as the etude isn’t completely boring and does scale up to some harmonics of the same note. The main takeaway is that it is easy figure out the melody of a song when there is only one instrument and the structure is very regimented as this etude is designed for a pianist to practice their arpeggios (set of notes played in an increasing frequency and then decreasing frequency corresponding to the intended melody for a song). 

![Figure72]({{ site.url }}/assets/images/figure7-2.PNG)

For track370-electronic.wav, it is just a random jumble of electronic sounds put together and from the chart we can see that as there is not really set structure, and there just seems to be noise at a wide variety of frequencies. It is unclear what the user should be listening to as there seems to be what sounds like drums tapping in quick succession, but it is generally overshadowed by the very electronic and unnatural sounds which vary a lot in frequency even just for less than a second of time. 

![Figure73]({{ site.url }}/assets/images/figure7-3.PNG)

Track396-electronic.wav has a very strong bass in the background which can be seen by all the red at low frequencies, it does however cut out around 120 seconds which does make sense as there is only the woman singing at that point in the song. As for the light red at higher frequencies, this can either be attributed to the woman’s voice of the other electronic instrumentation heard throughout the song that generates the melody. There is very quick switching between notes for the melody which is the primary reason that there seems to be a lot of noise for short periods of time. 

![Figure74]({{ site.url }}/assets/images/figure7-4.PNG)

In this jazz track we can hear something that sounds like a synthesizer and steady drums and symbols in the background. There is somewhat of a structure to the synthesizer which looks to repeat every 15 seconds, which makes sense as the musician uses the same series of 5 notes very often throughout the track. Near the end the structure seems to be loss which can be heard in the song as the musician decides to show off their skills and abandon the structure that was set at the beginning of the track. 

![Figure75]({{ site.url }}/assets/images/figure7-5.PNG)

For this jazz track, again the synthesizer seems to hold a steady pattern, but it is most difficult to see in this chart as the song is higher tempo (more fast-paced) as the drums are more high energy. Between 90 and 120 seconds the track seems to lose it’s rhythm which can be heard as the synthesizer start to vary it’s notes quite a bit and the drums become very soft. But the track pick right back up to the original rhythm right after. 

![Figure76]({{ site.url }}/assets/images/figure7-6.PNG)

For this metal track, there is a clear bass throughout the song, and a vocalist singing the melody. Looking at the Fourier transform, no real structure cannot be seen for this track, which is common in metal music and there is a lot of noise, but the rhythm is difficult to figure out as the bass keeps constantly changing the tempo of the song pretty sporadically. The song does seem to cover a wide range of frequencies as the majority of the plot is orange and red signifying a wide range of harmonics. 

![Figure77]({{ site.url }}/assets/images/figure7-7.PNG)

This metal track seems to have even more noise, and even though the bass seems to have a bit more structure than the previous track, but the structure does not retain after 30 seconds in the song. The plot is even more red than the previous range, which means every harmonic is equally strong which is quite impressive from this musician. From 60 to 90 seconds we can see some ripples, which could be attributed to the slides that can be heard in this area where it seems like an electric guitar is just sliding their finger quickly down the frets (lines on guitar to determine what note is played) to produce this unique sound. 

![Figure78]({{ site.url }}/assets/images/figure7-8.PNG)

In this rock track there seems to be a standard 4 notes that are played throughout the song which gives a structure in the lower frequencies that can kind of be seen, but since the 4 notes seem to happen at random intervals they are a bit difficult to see in the plot. At higher frequencies, we can see the woman’s voice as well as the harmonics that are produced with the other instruments in the background. 

![Figure79]({{ site.url }}/assets/images/figure7-9.PNG)

In this rock track, the structure is clear to see with the ukulele like instrument in the background as it plays a very melodic line that is easy to follow, the structure is more difficult to follow around 45 to 75 seconds and 110 and 155 seconds due to the woman’s voice and the additional harmonics which shows in the plot, but it is still pretty clear and there is just more noise which makes sense with the woman’s voice and ukulele going at the same time. 

![Figure710]({{ site.url }}/assets/images/figure7-10.PNG)

For this world track, the plot shows there is not much at the beginning which makes sense as it is just the running stream of water in the background. As the track goes on a flute is introduced which produces a steady tone, which can be seen by the dark red sections as low frequencies throughout the song. There is not much else in the song which the plot represents so we can safely say this plot is correct.

![Figure711]({{ site.url }}/assets/images/figure7-11.PNG)

For this world track we can see a steady structure in the plot, which can also be heard in the song. There are also clear harmonics which makes sense as it is just a couple instruments in the background. The song mostly follows the same structure throughout with some changes in frequency in the plot. Even though the sounds produces in the track might not be the most appealing to listen to, one can still hear a clear melody being played which is reflected in the plot.

![Figure712]({{ site.url }}/assets/images/figure7-12.PNG)

## Part 2: Power Spectroscopy 

Below are the plots generated by pspec. The code used to generate the plots is found in the appendix at the end of the report. Pspec takes in the sampled signal which is to be plotted. To change which window is used the second argument of stft inside the pspec function can be changed. The structure of these plots is very similar to those produced by stft. By squaring each data point the large values become larger and the small values become smaller making it easier to see where the salient features of each song are. All songs are analyzed individually in the following section and comments for the figures generated by pspec are included above each figure. 

In the power spec of track201-classical it can be seen that the song is centered around 50 Hz and harmonics of that frequency. This frequency is likely the note A, as the scale(series of notes the song is centered around) is A minor. 

![Figure713]({{ site.url }}/assets/images/figure7-13.PNG)

In track204-classical we can see that the power spec is centered around the notes that go up in frequency and less on the notes that going down in frequency. After listening to the song this makes sense as the volume of notes seems to increase proportionally to frequency as the frequency increases, and the volume also decreases when the pianist goes from high frequencies to low frequencies. 

![Figure714]({{ site.url }}/assets/images/figure7-14.PNG)

In track370-electronic we still see that the music is pretty random in the power spec plot. There is still a lot of noise throughout the track, with the track being very corrupted around 120 seconds to the end of the track. The beginning of the song seems to have lots of harmonics which makes sense for an electronic track, as well as some before the track gets corrupted which can kind of be heard, but not too well with all the other noise in the track. 

![Figure715]({{ site.url }}/assets/images/figure7-15.PNG)

Looking at the power spec of track306-electronic, the bass in the background is very clear to see, and there seems to be a lot of harmonics for different frequencies which explains the music sounding like there are many notes being played at once, as well as the woman's voice which likely has some vibrato(slight change in pitch in singer's voice) to generate the ripples seen below. 

![Figure716]({{ site.url }}/assets/images/figure7-16.PNG)

For track437-jazz, we can see that most of the track resides in the low frequencies which is noticeable, with a small spike at higher frequencies which can be attributed to the light brass sound from the symbols that are part of the drum set. 

![Figure717]({{ site.url }}/assets/images/figure7-17.PNG)

In track439-jazz the story is very similar to the previous track with most of the frequencies being on the low end on the synthesizer that starts the track, and small spikes at higher frequencies, and almost no high freqencies from 90 to 120 seconds as it is mostly just the syntheziser that can be heard. 

![Figure718]({{ site.url }}/assets/images/figure7-18.PNG)

Track463-metal still seems to be quite a mess, but at least with the power spec plot we can see a steady bass and potentially some harmonics throughout the song, but this still doesn't change the fact that it is very noisy in most places and the song doesn't have much structure. 

![Figure719]({{ site.url }}/assets/images/figure7-19.PNG)

Track492-metal is similar to the previous metal track in that it also has a lot of noise which makes it difficult to make any clear comments of what is important in the song. It seems there is heavy bass again, but all other frequencies are all over the place which makes sense as metal music has many varying notes being played at high tempos. 

![Figure720]({{ site.url }}/assets/images/figure7-20.PNG)

In the power spec plot for track 547-rock we can see a lot of the song centered between 0 and 50 Hz which is likely consistent of the woman's voice and some of the instruments and then further harmonics at higher frequencies likely produced from the instruments in the track. 

![Figure721]({{ site.url }}/assets/images/figure7-21.PNG)

For track550-rock we can cleary see the rhythmic structure of the track and where at 45 and 120 seconds the woman's voice comes in as well as the harmonics generated from this. This track is a lot easier to follow in the power spec plot than that of the metal tracks above. 

![Figure722]({{ site.url }}/assets/images/figure7-22.PNG)

For track707-world we can now clearly see where the flute changes harmonics and it is very clear what pitch the flute is playing at specific times through the power spec plot. However, we lose a lot of the features of the flowing water in the background with the power spec plot. 

![Figure723]({{ site.url }}/assets/images/figure7-23.PNG)

For track729-world we can see from the power-spec plot that the song is very low frequency with only a couple more harmonics that can be clearly heard in the track. We can see a light rhythmic structure but not cleary, as there is quite a bit going on throught the song to define this absolutely. 

![Figure724]({{ site.url }}/assets/images/figure7-24.PNG)

## Parts 3 and 4: Peak Power

Below are the plots for peakpwr. The code used to generate the plots is found in the appendix at the end of the report. Peakpwr takes in the sampled signal being plotted. Only the cell with the maximum value is preserved in each column, this is the most prominent frequency in this section of 1024 samples. We only look at frequencies under 70 Hz in our plots as most of the maximums are between the range of 0-70 Hz. All songs are analyzed individually in the following section and comments for the figures generated by peakpwr are included above each figure.

In track201-classical we see that the peak power as there are sections where the violin dominates and other sections where the low frequency of the cello dominates for the concerto. There are two frequencies where the peak power is very prevalent which is likely to be the frequency corresponding to the tone of A as this song is in A minor. 

![Figure725]({{ site.url }}/assets/images/figure7-25.PNG)

In track204-classical there are about 3 frequencies that make up most of the peak power in this song which makes sense as the pianist is mostly playing a series of 3 notes known as arpeggios throughout the song which is reflected in the chart. 

![Figure726]({{ site.url }}/assets/images/figure7-26.PNG)

The peak power for track370-electronic is all over the place which makes sense as the previous graphs did not show much structore to this track, and the chart shows a pretty even distribution among a wide range of frequencies that have peak power at a given time. 

![Figure727]({{ site.url }}/assets/images/figure7-27.PNG)

The peak power for track396-electronic shows a lot of peak power at the lower frequencies as the steady bass is dominant in the background for a lot of the track. This makes sense as it is about the only thing there is in the track until the woman's voice comes in from 120 to 180 seconds and that becomes the only thing that can be heard clearly. 

![Figure728]({{ site.url }}/assets/images/figure7-28.PNG)

We can see the peak power starting at around 30Hz for track437-jazz which makes sense as there is the steady tone at the beginning of the song, but then the lower frequencies seem to dominate afterwards which can be heard with the drums in the background. 

![Figure729]({{ site.url }}/assets/images/figure7-29.PNG)

In track 439-jazz the peak power seems to be more varied which is expected as the synthsizer is playing a wide range of notes and the drums are very upbeat and compete with each other in terms of how load they are in the song. 

![Figure730]({{ site.url }}/assets/images/figure7-30.PNG)

In track463-metal the peak power is again all over the place with no single frequency really dominating the entire song, and this was to be expected from the previous plots as there is a lot going on in the song which makes its structure difficult to follow.

![Figure731]({{ site.url }}/assets/images/figure7-31.PNG)

The peak power for track492-metal is similar to the previous metal track, but there seems to be a clearer bass frequency throughout the song with some higher frequencies having peak power as well. 

![Figure732]({{ site.url }}/assets/images/figure7-32.PNG)

For track547-rock the low frequency around 9Hz seems to dominate most of the track, while high frequencies are included in the peak power whenever the human voice comes into the track which can be heard in the track and seen in the plot. 

![Figure733]({{ site.url }}/assets/images/figure7-33.PNG)

For track550-rock it seems the woman's voice dominates the peak power plot with some slight changes in frequency at point, which can be attributed to the vibrato that can be heard in her voice where she changes pitch ever so slightly throughout the song. 

![Figure734]({{ site.url }}/assets/images/figure7-34.PNG)

For track707-world, we can clearly see the harmonics produced by the flute in the track with the peak power track and when the flute changes harmonics starting at lower frequencies then going to higher ones then going back to lower ones. 

![Figure735]({{ site.url }}/assets/images/figure7-35.PNG)

For track729-world we see most of the peak power around 39 Hz and 32 Hz which makes sense as the instruments in the song seem to be low frequency instruments where this frequency is reasonable. However, the peak power is still pretty random as there are a few variances where unexpected notes show up in the peak power plot. 

![Figure736]({{ site.url }}/assets/images/figure7-36.PNG)

## Part 5: Instantaneous Frequency

![Figure737]({{ site.url }}/assets/images/figure7-37.PNG)

Here we see the instantaneous frequency of the signal chirp as defined in createsound.m. We see that the song starts out in the 2500 Hz area goes to 1200 Hz and ends around 3200 Hz. We can also tell this is a very pure tone as it is clear where the sinusoid is shifting. We also expected this behavior from listening to the signal and the frequency slightly increases at the beginning, then drops significantly then sharply increases at the end which we see in this plot of the instantaneous frequency.

![Figure738]({{ site.url }}/assets/images/figure7-38.PNG)

Here in piano chroma we can see the edges where the frequency increases as we approach the end of the chromatic scale. As the piano is much less of a pure tone with other frequencies as a result of a mallet striking a string, the vibrations of the string cause residual frequencies that aren’t the intended key/pitch being played. We can also see that the frequency grows in a logarithmic fashion rather than a linear fashion from the edge detection. 

![Figure739]({{ site.url }}/assets/images/figure7-39.PNG)

For metal we can see a lot of bumps unlike for piano chroma which is likely due to the person in the song running out of oxygen from screaming each time. We do not see a very smooth correlation between a time in the song where the frequencies sync up with noticeable harmonics. This could be troublesome for relating a song to another song as there is not a prevalent frequency if we decide to determine a song’s important features using frequency. 

## Part 6: Cover Song Identification

Songs, even if performed by different artists, will share a melody. This is what our program cover.m utilizes in order to pair a song with its cover. We were given 5 songs and a cover for each of those songs. To find the melody of each song provided, the energy of each semitones is calculated for each set of 2048 samples. This intensity is quantified using our chromatic.m function and stored in a matrix. The matrices produced by chromatic.m can be seen in the figures below. The values stored in these matrices are compared using our cover.m function, applying the corr function in MATLAB and a shift function we are able to do this. Each song is compared to every other song in the track list and the value is stored in a matrix “score” which can be seen below.

![Figure740]({{ site.url }}/assets/images/figure7-40.PNG)

A higher value means the song is more strongly correlated with another. The diagonal is the comparison between a song and itself, these are all a value of 1 meaning there is perfect correlation which is to be expected. From our matrix, the songs most correlated with one another are:

![Figure741]({{ site.url }}/assets/images/figure7-41.PNG)

1 and a as well as 5 and e having the strongest correlation with one another. These pairs are covers of one another showing our function has proper functionality. Othe the other 3 pairs the only others properly paired are 4 and d but this is not a strong correlation. To further inspect the quality of our correlation function choma-graphs of various songs can be seen below. 

![Figure742]({{ site.url }}/assets/images/figure7-42.PNG)

Track 1 and track a were designated by our score.m function as strongly correlated. Track a is a cover of track 1, this is an example our function working. Key similarities between the tacks are the lack of intensity in the C# semitone especially around the 5000th frame. C, E, and G are the most populated tones in both songs, this exemplifies a C major chord. 

![Figure743]({{ site.url }}/assets/images/figure7-43.PNG)

Track b is a cover of track 2; however, the correlation calculated from our function was low and the highest correlation for track 2 was with track c. The cover is one key higher than the original, this should not be a problem for our function because we shifted the matrices containing the semitone intensities by one in either direction to account for this change. We presume the differences in intensity provided enough correlation between the semitones of a non-shifted set of data that our function could not determine that b was a cover of 2. 

![Figure744]({{ site.url }}/assets/images/figure7-44.PNG)

The cover of track 3 is track c and track e is a cover for track 5. Our program incorrectly gave us a relatively high correlation between these two tracks. In this case, we believe our shift function optimized the correlation between these two tracks. Visually, G in track 3 and F# in track e appear to similar in addition to A# from track 3 and A in track e. Shifting track 3 down one key could would aline these similarities and explain the high correlation between two different songs. 

## Appendix Parts 1-4

This is the main function used to generate all plots for the report for parts 1-4 as well as documentation for how to generate those same plots using the different windows: Blackman and Kaiser.  

**Main script parts 1-4**

```
close all;
clear all;
clc;
filename = dir('*.wav');
numofSongs = length(filename);
for i = 1:numofSongs
	%for j = 1:3
	%use loop above to run through each window: 1) Hann 2) Blackman 3) Kaiser
	%Part 1
	[W, size_x] = stft(filename(i).name, 1);
	W_abs = 10*log10(abs(W));
	%Part 2
	P = pspec(filename(i).name);
	P_abs = 10*log10(abs(P));
	%Part 3
	PP = peakpwr(filename(i).name);
	PP_abs = 10*log10(abs(PP));
	%colormap jet
	%imagesc(PP_abs)
	%caxis ([-40 20])
	%colorbar
	%P = pspec(filename);
	%PP = peakpwr(filename);
	%plot and save all imagesc needed for report
	h = figure;
	W_abs = 10*log10(abs(W));
	xticklabels = 0:30:round(size_x);
	xticks = linspace(1, size(W_abs, 2), numel(xticklabels));
	colormap jet
	imagesc(W_abs)
	caxis ([-40 20])
	colorbar
	set(gca, 'YDir', 'normal', 'XTick', xticks, 'XTickLabel',xticklabels)
	xlabel('Time (seconds)');
	ylabel('Frequency (Hz)');
	title({'Fourier Transform of track: ', filename(i).name});
	saveas(gca,['Abs(y)', filename(i).name ,  '.png']);
	close(h);
	h = figure;
	xticklabels = 0:30:round(size_x);
	xticks = linspace(1, size(W_abs, 2), numel(xticklabels));
	colormap jet
	imagesc(P_abs)
	caxis ([-40 20])
	colorbar
	set(gca, 'YDir', 'normal', 'XTick', xticks, 'XTickLabel',xticklabels)
	xlabel('Time (seconds)');
	ylabel('Frequency (Hz)');
	title({'Power Spec of track: ', filename(i).name});
	saveas(gca,['P(y)', filename(i).name ,  '.png']);
	close(h);
	h = figure;
	xticklabels = 0:30:round(size_x);
	xticks = linspace(1, size(W_abs, 2), numel(xticklabels));
	colormap jet
	imagesc(PP_abs)
	caxis ([-40 -20])
	ylim([0 50])
	colorbar
	set(gca, 'YDir', 'normal', 'XTick', xticks, 'XTickLabel',xticklabels)
	xlabel('Time (seconds)');
	ylabel('Frequency (Hz)');
	title({'Peak Power of track: ', filename(i).name});
	saveas(gca,['PP(y)', filename(i).name ,  '.png']);
	close(h);
end
```

**stft.m**

```
function [W, size_x] = stft(x,window)
%stft takes the fourier transform of an audio signal x
%and returns a 'time-frequency' matrix W where W is the Fourier
%transform of the windowed frame xn
x = audioread(x); % gets the samples of the file 'x'
N = 1024;
nframes = floor(2*length(x)/N);
xn = buffer(x,N, N/4); %creates overlapping samples of size N/4
W = zeros(N/2 + 1, length(xn));
size_x = length(x)/11025; %used to express samples in seconds for plots
switch window
	case 1
    	w=hann(N); % Hann (Hanning) window
	case 2
    	w=blackman(N); % Blackman window
	case 3
    	w=kaiser(N, 0.5); % Kaiser window
	otherwise
    	w=kaiser(N, 0.5); % defaults to Kaiser window
end
for i = 1:length(xn)
	Y(:,i) = fft(xn(:,i).*w); %compute the fast Fourier transform
end
	K = N/2 + 1;
for i = 1:length(xn)
	W(1:K,i) = Y(1:K,i); %generate the 'time-frequency matrix W
end
end
```

**pspec.m**

```
function [P] = pspec(x)
%function pspec computes the magnitude squared of the
%Fourier transform of frame n
i = stft(x,1);
P = abs(i);
P = P.^2;
end
```

**peakpwr.m**

```
function [PP] = peakpwr(x)
%peakpwr finds the maximum of pspec of frame n
x = pspec(x);
PP = zeros(size(x));
 
for i = 1:length(x)
	[values,locations] = max(x(:,i));
	PP(locations,i) = values;
end
```

## Appendix Parts 5-6

**Main script parts 5-6**

```
close all;
clear all;
clc;
%generate file names
filename = dir('*.wav');
numofSongs = length(filename);
%for loop goes through all the tracks
for i = 1:10
	[x,y] = audioread(filename(i).name); %read track
	[iFz,frameSize, nFrames] = ifz_3(x',y,2048); %take the IF
	[W,size_t] = stft_2(x,fs,4); %takes stft
	W_abs = 10*log10(abs(W));
	C(:,:,i) = chromatic(x',y, 1024);  %takes chroma/NPCP
	c_sum(:,i) = sum(C(:,:,i), 2);
	%generate plots for IF
	h = figure;
	xticklabels = 0:60:ceil(length(x)/y);
	yticklabels = 0:500:ceil(y/2);
	xticks = linspace(1, nFrames, numel(xticklabels));
	yticks = linspace(1, frameSize, numel(yticklabels));
	axis xy;
	colormap jet
	imagesc(iFz)
	caxis ([1200 3200])
	c = colorbar;
	c.TicksMode = 'manual';
	c.Ticks = [-2000 0 2000 4000 6000 8000];
	c.TickLabelsMode = 'manual';
	c.TickLabels = {'-2000', '0', '2000', '4000', '6000', '8000'};
	set(gca, 'YDir', 'normal');
	xlabel('Time (seconds)');
	ylabel('Frequency (Hz)');
	title({'Instantaneous frequency of track: ' filename(i).name});
	saveas(gca,['Chroma(y)', filename(i).name ,  '.png']);
	close(h);
	%generate chroma plots
	h=figure;
	C_abs = 10*log10(abs(C));
	imagesc(flipud(C_abs));
	ax=gca;
	ax.YTickLabel=fliplr({'A ','A#','B ','C ','C#','D ','D#','E ',...
    	'F ','F#','G ','G#'});
	ax.YTick=linspace(1,12,12);
	colormap 'jet';
	title({'Chroma :'; filename(i).name});
	xlabel('frames');
	ylabel('Note');
	colorbar;
	caxis([-60 0])
	saveas(gca,['NPCP' filename(i).name '.png']);
	close(h);
end
 
% [x1,fs] = audioread('1.wav');
% x2 = audioread('3.wav');
%
% [C1] = chromatic(x1',fs,1024);
% [C2] = chromatic(x2',fs,1024);
%
% c1 = sum(C1,2);
% c2 = sum(C2,2);
%
% CC = corr(C1',C1');
% cc = diag(CC);
% score = sum(abs(cc));
% C_1 = C(:,:,1);
% C_2 = C(:,:,2);
%generate correlation matrix for the 10 cover songs
```

**cover.m**

```
%generate correlation matrix for the 10 cover songs
function[score] = cover(C)
for i = 1:10
	for j = 1:10
    	%shift code in case 1 track is transposed from another track
    	c1 = sum(C(:,:,i), 2);
    	c2 = sum(C(:,:,j), 2);
    	shift = zeros(3,1);
    	shift(1) = corr(c1(2:12), c2(1:11));
    	shift(2) = corr(c1(1:11), c2(1:11));
   	 shift(3) = corr(c1(1:11), c2(2:12));
    	[dummy, ishift] = max(shift);
    	switch ishift
        	case 1
            	D(1:11,:,i) = C(2:12,:,i); D(12,:,i) = C(1,:,i); C(:,:,i) = D(:,:,i);
        	case 3
            	D(1:11,:,j) = C (2:12,:,j); D(12,:,j) = C(1,:,j); C(:,:,j) = D(:,:,j);
    	end
    	CC = corr((C(:,:,i)'), (C(:,:,j)')); %calulate correlation
    	cc = diag(CC); %diag to remove uneccesary functions
    	score(i,j) = sum(abs(cc));
    	score(i,i) = 1; %produce score
    	imagesc(score);
	end
end
end
```

**createsound.m**

```
sizex = 1e5;
fs = 1e4;
t = [1:sizex]/fs;
phi = 2*pi*(2000*t.*(1 + 0.1*sin(2*pi.*0.1*t)));
x = cos (phi);
x = x';
%audiowrite('chirp.wav', x, fs);
```

**ifz.m**

```
function[iFz, frameSize,nFrames] = ifz_3(signal,samplingRate,lengthFFT)
%function ifz_3 calculates the instantaneous frequency of a vector of
%signal from a song, samplingRate is the sampling rate of the song,
%lengthFFT is the number of frames used to caclculate the instantaneous
%frequency
frameSize  = lengthFFT/2; % overlap by N/2 frames
frameSize2 = lengthFFT/4;
s = length(signal);
nFrames = 1 + floor((s - (frameSize))/(frameSize2)); %number of frames to anaylze
T = (frameSize)/samplingRate;
win = 0.5*(1-cos([0:((frameSize)-1)]/(frameSize)*2*pi)); %raised cosing window
dwin = -pi / T * sin([0:((frameSize)-1)]/(frameSize)*2*pi);
iFz = zeros(frameSize,1);
iFz = zeros(frameSize, nFrames);
S   = zeros(frameSize, nFrames);
 
nmw1 = floor(frameSize2);
nmw2 = frameSize - nmw1;
 
omega = 2*pi*[0:(lengthFFT-1)]*samplingRate/lengthFFT; %base frequency
 
%for loop to calculate instantaneous frquency
for ifrm = 1:nFrames
	
	u = signal((ifrm-1)*(frameSize2) + [1:(frameSize)]);
 
	wu = win.*u; du = dwin.*u;
 
	wu = [zeros(1,nmw1),wu,zeros(1,nmw2)];
	du = [zeros(1,nmw1),du,zeros(1,nmw2)];
 
	DU = fft(fftshift(du));
	WU = fft(fftshift(wu));
 
	domega = imag(DU .* conj(WU)) ./(abs(WU).*abs(WU) + (abs(WU)==0));
 
	ifz = (omega + domega)./(2*pi);
	iFz (:,ifrm) = ifz(1:frameSize)';
	%S   (:,ifrm) = WU(1:frameSize)'*norm;
end
end
```

**chromatic.m**

```
function [C] = chromatic (signal,samplingRate,lengthFFT)
%  Computes the 12 x nframes chroma representation
%  The computation procedes in two steps:
%	1) an estimate of the instantaneous frequency is computed using the derivative of the
%	phase.
%	2) the energy associated with the instantaneous frequency is folded back into the octave
%	defined by A0.
%
% INPUT:
%      	signal: a row vector of size 1 x nsamples
%      	samplingRate: the sampling rate in Hz
%      	lengthFFT: the length of each FFT analysis, this is N in the project guidebook
%
% OUTPUT:
%      	C: matrix of chroma of size 12 x (2*(nsamples/lengthFFT -1)) if the overlap between
%      	the windows is lengthFFT/2.
 
if (size (signal,1) > size(signal,2))
	error (['Error in chromatic: \n'...
        	'\tThe input variable %s is currently a column vector. \n\tIt should be a row vector.\n'...
        	'\tPlease consider transposing %s.'],inputname(1), inputname(1));
end
A0   = 27.5;
nchr = 12;                          	% number of semi tones
 
% parameters of the Fourier analysis
frameSize  = lengthFFT/2;
frameSize2 = lengthFFT/4;
 
% get the number of frames
 
s = length(signal);
nFrames = 1 + floor((s - (frameSize))/(frameSize2));
 
T = (frameSize)/samplingRate;
 
% build the window for the analysis
 
win = 0.5*(1-cos([0:((frameSize)-1)]/(frameSize)*2*pi));
dwin = -pi / T * sin([0:((frameSize)-1)]/(frameSize)*2*pi);
 
% used later for normalizing purposes
norm = 2/sum(win);
 
% memory allocation
 
iFz = zeros(frameSize,1);
iFz = zeros(frameSize, nFrames);
S   = zeros(frameSize, nFrames);
 
nmw1 = floor(frameSize2);
nmw2 = frameSize - nmw1;
 
omega = 2*pi*[0:(lengthFFT-1)]*samplingRate/lengthFFT;
 
% computation of the instantaneous frequency, using the analytical expression of the derivative of the phase
 
for ifrm = 1:nFrames
	
	u = signal((ifrm-1)*(frameSize2) + [1:(frameSize)]); 
	wu = win.*u; du = dwin.*u;
 
	wu = [zeros(1,nmw1),wu,zeros(1,nmw2)];
	du = [zeros(1,nmw1),du,zeros(1,nmw2)];
 
	DU = fft(fftshift(du));
	WU = fft(fftshift(wu));
 
	domega = imag(DU .* conj(WU)) ./(abs(WU).*abs(WU) + (abs(WU)==0));
 
	ifz = (omega + domega)./(2*pi);
	iFz (:,ifrm) = ifz(1:frameSize)';
	S   (:,ifrm) = WU(1:frameSize)'*norm;
end;
 
% now we find the local maxima of the instantaneous frequency
 
f_ctr = 1000;
f_sd = 1;
 
f_ctr_log = log2(f_ctr/A0);
fminl  = oct2hz(hz2oct(f_ctr)-2*f_sd);
fminu  = oct2hz(hz2oct(f_ctr)-f_sd);
fmaxl  = oct2hz(hz2oct(f_ctr)+f_sd);
fmaxu  = oct2hz(hz2oct(f_ctr)+2*f_sd);
 
minbin  = round(fminl * (lengthFFT/samplingRate) );
maxbin = round(fmaxu * (lengthFFT/samplingRate) );
 
% compute the first order derivative along the  frequency direction to detect plateaux
ddif	= [iFz(2:maxbin, :);iFz(maxbin,:)] - [iFz(1,:);iFz(1:(maxbin-1),:)];
 
% detect the frequencies around which the IF is changing very slowly, if at all
dgood = abs(ddif) < .75*samplingRate/lengthFFT;
dgood = dgood .* ([dgood(2:maxbin,:);dgood(maxbin,:)] >  0 | [dgood(1,:);dgood(1:(maxbin-1),:)] > 0);
 
p = zeros(size(dgood));
m = zeros(size(dgood));

%  try to fit a second order polynomial locally
for t = 1:size(iFz,2)
	ds = dgood(:,t)';
	lds = length(ds);
 
	st = find(([0,ds(1:(lds-1))]==0) & (ds > 0));
	en = find((ds > 0) & ([ds(2:lds),0] == 0));
	npks = length(st);
	frqs = zeros(1,npks);
	mags = zeros(1,npks);
 
	for i = 1:length(st)
    	bump = abs(S(st(i):en(i),t));
    	frqs(i) = (bump'*iFz(st(i):en(i),t))/(sum(bump)+(sum(bump)==0));
    	mags(i) = sum(bump);
 
    	if frqs(i) > fmaxu
        	mags(i) = 0;
        	frqs(i) = 0;
    	elseif frqs(i) > fmaxl
        	mags(i) = mags(i) * max(0, (fmaxu - frqs(i))/(fmaxu-fmaxl));
    	end
 
    	if frqs(i) < fminl
        	mags(i) = 0;
        	frqs(i) = 0;
    	elseif frqs(i) < fminu
        	mags(i) = mags(i) * (frqs(i) - fminl)/(fminu-fminl);
    	end
    	if frqs(i) < 0
        	mags(i) = 0;
        	frqs(i) = 0;
    	end
	end
 
	bin = round((st+en)/2);
	p(bin,t) = frqs;
	m(bin,t) = mags;
end
 
ncols = size (p,2);
 
Pocts = hz2oct(p+(p==0));
Pocts(p(:)==0) = 0;
 
nzp = find(p(:)>0);
 
[hn,hx]  = hist(nchr*Pocts(nzp)-round(nchr*Pocts(nzp)),100);
centsoff = hx(find(hn == max(hn)));
 
Pocts(nzp) = Pocts(nzp) - centsoff(1)/nchr;
 
PoctsQ = Pocts;
PoctsQ(nzp) = round(nchr*Pocts(nzp))/nchr;
 
Pmapc = round(nchr*(PoctsQ - floor(PoctsQ)));
Pmapc(p(:) == 0) = -1;
Pmapc(Pmapc(:) == nchr) = 0;

C = zeros(nchr,ncols);
for t = 1:ncols; C(:,t)=(repmat([0:(nchr-1)]',1,size(Pmapc,1))==repmat(Pmapc(:,t)',nchr,1))*m(:,t);
end
return;
 
function [oct] = hz2oct(freq, A440)
if nargin < 2;  
	A440 = 440;
end
oct = log(freq./(A440/16))./log(2);
return;
 
 
function [hz] = oct2hz(octs,A440)
if nargin < 2;  
	A440 = 440;
end
hz = (A440/16).*(2.^octs);
Return;
```






